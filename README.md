# ‚öôÔ∏è MACHINE LEARNING: OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS

[![Python](https://img.shields.io/badge/Python-3670A0?style=flat&logo=python&logoColor=ffdd54)](https://www.python.org/)¬†¬†
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)¬†¬†
[![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white)](https://pandas.pydata.org/)

Este proyecto aborda una etapa avanzada y cr√≠tica en Machine Learning: la **Optimizaci√≥n de Hiperpar√°metros**. Se enfoca en mejorar el rendimiento y la capacidad de generalizaci√≥n de un modelo predictivo, como un **√Årbol de Decisi√≥n**, al encontrar la mejor combinaci√≥n de sus par√°metros internos (hiperpar√°metros).

---

## üß† Contenido del Proyecto

### 1Ô∏è‚É£ El Problema de la Optimizaci√≥n
- **Hiperpar√°metros vs. Par√°metros:** Los **par√°metros** son aprendidos por el modelo a partir de los datos (ej. pesos en una regresi√≥n), mientras que los **hiperpar√°metros** son definidos *antes* del entrenamiento (ej. la profundidad m√°xima de un √°rbol).
- **Impacto:** Una mala elecci√≥n de hiperpar√°metros puede llevar al **sobreajuste (*overfitting*)** o al **subajuste (*underfitting*)**, resultando en un modelo in√∫til.

### 2Ô∏è‚É£ Dataset y Modelo de Referencia
- **Dataset:** Se utiliza un dataset de veh√≠culos que incluye el **precio**, el estado de **venta** (`vendido: 1/0`), la **edad del modelo** y los **kil√≥metros por a√±o**.
- **Modelo Inicial:** Se establece un modelo de clasificaci√≥n inicial (probablemente un **√Årbol de Decisi√≥n**) con hiperpar√°metros por defecto para medir su rendimiento base antes de la optimizaci√≥n.

### 3Ô∏è‚É£ M√©todos de Optimizaci√≥n de Hiperpar√°metros
El proyecto implementa y compara dos estrategias principales para la b√∫squeda del mejor conjunto de hiperpar√°metros:

#### A. B√∫squeda por Grilla (Grid Search)
- **Concepto:** Consiste en definir una **grilla exhaustiva** (un diccionario de todas las combinaciones posibles de hiperpar√°metros) y entrenar el modelo con *cada* combinaci√≥n.
- **Herramienta:** Se utiliza `GridSearchCV` de Scikit-learn, combin√°ndolo con la **Validaci√≥n Cruzada** (`K-Fold`) para evaluar de forma robusta cada combinaci√≥n y elegir la mejor.
- **Resultado:** Garantiza encontrar el mejor conjunto dentro de la grilla definida.

#### B. B√∫squeda Aleatoria (Random Search)
- **Concepto:** En lugar de probar todas las combinaciones, `Random Search` prueba un **subconjunto aleatorio** de combinaciones dentro de un rango definido.
- **Ventaja:** Es mucho m√°s **r√°pida** y eficiente en t√©rminos de recursos computacionales que `Grid Search`, especialmente cuando el n√∫mero de hiperpar√°metros es grande.

### 4Ô∏è‚É£ Optimizaci√≥n del √Årbol de Decisi√≥n
Se optimizan hiperpar√°metros clave del √Årbol de Decisi√≥n, como:
- `max_depth` (Profundidad m√°xima del √°rbol)
- `min_samples_leaf` (N√∫mero m√≠nimo de muestras en un nodo hoja)
- `criterion` (Funci√≥n para medir la calidad de una divisi√≥n, ej. Gini o Entrop√≠a).

---

## üõ†Ô∏è Librer√≠as Utilizadas

| Librer√≠a | Uso principal |
|:---:|:---:|
| **Scikit-learn** | Implementaci√≥n de modelos (`DecisionTree`), `GridSearchCV`, `RandomizedSearchCV` y m√©tricas|
| **Pandas** | Carga y manipulaci√≥n de los datos del mercado de veh√≠culos |

---

## üéØ Objetivo del Proyecto
El objetivo es dominar las t√©cnicas de **optimizaci√≥n autom√°tica** para refinar y mejorar modelos de Machine Learning. El proyecto ense√±a cu√°ndo y c√≥mo utilizar **Grid Search** y **Random Search** para maximizar el rendimiento de un modelo, garantizando que el modelo final no solo sea preciso sino que tambi√©n generalice bien a datos no vistos.

---

## üìà Resultados Clave
- Se demuestra la **mejora en el rendimiento** (ej. mayor `Accuracy` o `F1-Score`) despu√©s de aplicar la optimizaci√≥n de hiperpar√°metros en comparaci√≥n con el modelo base.
- Se identifica y aplica el **mejor conjunto de hiperpar√°metros** encontrado, lo que minimiza el riesgo de sobreajuste.
- Se proporciona una comprensi√≥n pr√°ctica de la **compensaci√≥n entre la exhaustividad (Grid Search) y la eficiencia (Random Search)** en la optimizaci√≥n de modelos.

